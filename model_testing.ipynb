{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5abaff5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0+cu128\n",
      "True\n",
      "0\n",
      "NVIDIA GeForce RTX 4070 Laptop GPU\n",
      "12.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ea68274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea1a0756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_model import CustomCNN, evaluate_model, evaluate_with_tta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b08d94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['buildings', 'forest', 'mountain', 'sea', 'street']\n",
      "Test accuracy: 95.12%\n"
     ]
    }
   ],
   "source": [
    "# Load the checkpoint\n",
    "checkpoint = torch.load('/home/muhammad_adib/imgclass_cnn/intel_cnn_model.pth', map_location=device)\n",
    "\n",
    "# Re-initialize the model architecture (must match the saved model)\n",
    "model = CustomCNN(num_classes=len(checkpoint['class_names'])).to(device)\n",
    "\n",
    "# Load the saved weights\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Set to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Access saved information\n",
    "print(f\"Classes: {checkpoint['class_names']}\")\n",
    "print(f\"Test accuracy: {checkpoint['test_accuracy']*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b20c778a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class names: ['buildings', 'forest', 'mountain', 'sea', 'street']\n",
      "Number of classes: 5\n",
      "Total images: 14063\n",
      "Training set: 9843\n",
      "Validation set: 2110\n",
      "Test set: 2110\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "\n",
    "# Image size - must be consistent across train and validation\n",
    "IMG_SIZE = 150  # Use same size for both\n",
    "\n",
    "# 1. Define your two different sets of transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),  # Same size as training!\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 2. Load the base dataset (no transform yet)\n",
    "path = '/home/muhammad_adib/imgclass_cnn/Data'\n",
    "base_dataset = datasets.ImageFolder(root=path)\n",
    "\n",
    "# 3. Get stratified indices\n",
    "# 70-15-15 split\n",
    "train_val_idx, test_idx = train_test_split(\n",
    "    np.arange(len(base_dataset.targets)),\n",
    "    test_size=0.15, # 15% for test\n",
    "    stratify=base_dataset.targets,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_idx, val_idx = train_test_split(\n",
    "    train_val_idx,\n",
    "    test_size=0.1765, # ~15% of original data for validation\n",
    "    stratify=[base_dataset.targets[i] for i in train_val_idx],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 4. Create subsets and manually attach the transforms\n",
    "# We use a simple wrapper class or just apply them via Subset\n",
    "class ApplyTransform(torch.utils.data.Dataset):\n",
    "    def __init__(self, subset, transform=None):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.subset[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "train_dataset = ApplyTransform(Subset(base_dataset, train_idx), transform=train_transform)\n",
    "val_dataset = ApplyTransform(Subset(base_dataset, val_idx), transform=val_transform)\n",
    "test_dataset = ApplyTransform(Subset(base_dataset, test_idx), transform=val_transform)\n",
    "\n",
    "# 5. DataLoaders - Using num_workers=0 to avoid BrokenPipeError\n",
    "# For RTX 4070, GPU is fast enough that this won't be a bottleneck\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, pin_memory=True)\n",
    "\n",
    "# Get class names\n",
    "class_names = sorted(os.listdir(path))\n",
    "num_classes = len(class_names)\n",
    "print(f\"\\nClass names: {class_names}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "print(f\"Total images: {len(base_dataset)}\")\n",
    "print(f\"Training set: {len(train_dataset)}\")\n",
    "print(f\"Validation set: {len(val_dataset)}\")\n",
    "print(f\"Test set: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52ea5d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 33/33 [00:04<00:00,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.9512 (95.12%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   buildings       0.91      0.92      0.91       394\n",
      "      forest       1.00      0.98      0.99       411\n",
      "    mountain       0.94      0.98      0.96       456\n",
      "         sea       0.98      0.94      0.96       416\n",
      "      street       0.94      0.93      0.93       433\n",
      "\n",
      "    accuracy                           0.95      2110\n",
      "   macro avg       0.95      0.95      0.95      2110\n",
      "weighted avg       0.95      0.95      0.95      2110\n",
      "\n",
      "\n",
      "Test Accuracy: 95.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = evaluate_model(model, test_loader, class_names)\n",
    "print(f\"\\nTest Accuracy: {test_accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d5aa4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final TTA Accuracy: 95.21%\n",
      "TTA Test Accuracy: 95.21%\n"
     ]
    }
   ],
   "source": [
    "tta_accuracy = evaluate_with_tta(model, test_loader, device)\n",
    "print(f\"TTA Test Accuracy: {tta_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6952c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imgclass_cnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
