{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5006ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "class IntelImageDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for Intel Image Classification\"\"\"\n",
    "    \n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = sorted(os.listdir(root_dir))\n",
    "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}\n",
    "        \n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for class_name in self.classes:\n",
    "            class_path = os.path.join(root_dir, class_name)\n",
    "            if os.path.isdir(class_path):\n",
    "                for img_name in os.listdir(class_path):\n",
    "                    if img_name.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                        self.images.append(os.path.join(class_path, img_name))\n",
    "                        self.labels.append(self.class_to_idx[class_name])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "\n",
    "class CustomCNN(nn.Module):\n",
    "    \"\"\"Custom CNN architecture for image classification\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=6):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        \n",
    "        # First convolutional block\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.25)\n",
    "        )\n",
    "        \n",
    "        # Second convolutional block\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.25)\n",
    "        )\n",
    "        \n",
    "        # Third convolutional block\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.25)\n",
    "        )\n",
    "        \n",
    "        # Fourth convolutional block\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.25)\n",
    "        )\n",
    "        \n",
    "        # Adaptive pooling to handle different input sizes\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((4, 4))\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512 * 4 * 4, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=50, early_stopping_patience=10):\n",
    "    \"\"\"Train the model with early stopping\"\"\"\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    best_model_weights = None\n",
    "    patience_counter = 0\n",
    "    \n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    lr_history = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 60)\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        train_pbar = tqdm(train_loader, desc='Training')\n",
    "        for inputs, labels in train_pbar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            train_pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accs.append(epoch_acc)\n",
    "        \n",
    "        print(f'Train Loss: {epoch_loss:.4f} | Train Acc: {epoch_acc:.4f}')\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_pbar = tqdm(val_loader, desc='Validation')\n",
    "            for inputs, labels in val_pbar:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_running_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "                \n",
    "                val_pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        val_epoch_loss = val_running_loss / len(val_loader.dataset)\n",
    "        val_epoch_acc = accuracy_score(val_labels, val_preds)\n",
    "        val_losses.append(val_epoch_loss)\n",
    "        val_accs.append(val_epoch_acc)\n",
    "        \n",
    "        print(f'Val Loss: {val_epoch_loss:.4f} | Val Acc: {val_epoch_acc:.4f}')\n",
    "        \n",
    "        # Learning rate scheduling\n",
    "        scheduler.step(val_epoch_loss)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            lr_history.append(param_group['lr'])\n",
    "        \n",
    "        # Early stopping and model checkpointing\n",
    "        if val_epoch_acc > best_val_acc:\n",
    "            best_val_acc = val_epoch_acc\n",
    "            best_model_weights = model.state_dict().copy()\n",
    "            patience_counter = 0\n",
    "            print(f'âœ“ New best validation accuracy: {best_val_acc:.4f}')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f'Patience: {patience_counter}/{early_stopping_patience}')\n",
    "        \n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            print(f'\\nEarly stopping triggered after {epoch+1} epochs')\n",
    "            break\n",
    "    \n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_weights)\n",
    "    \n",
    "    return model, train_losses, train_accs, val_losses, val_accs, lr_history\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, class_names):\n",
    "    \"\"\"Evaluate the model on test set\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        test_pbar = tqdm(test_loader, desc='Testing')\n",
    "        for inputs, labels in test_pbar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    test_acc = accuracy_score(all_labels, all_preds)\n",
    "    print(f'\\nTest Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)')\n",
    "    \n",
    "    print('\\nClassification Report:')\n",
    "    print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "    \n",
    "    return test_acc\n",
    "\n",
    "\n",
    "def plot_training_history(train_losses, train_accs, val_losses, val_accs):\n",
    "    \"\"\"Plot training history\"\"\"\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot losses\n",
    "    ax1.plot(train_losses, label='Train Loss')\n",
    "    ax1.plot(val_losses, label='Val Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Training and Validation Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Plot accuracies\n",
    "    ax2.plot(train_accs, label='Train Acc')\n",
    "    ax2.plot(val_accs, label='Val Acc')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_title('Training and Validation Accuracy')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/home/muhammad_adib/imgclass_cnn/training_history.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"\\nTraining history plot saved as 'training_history.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f12b71",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for CustomCNN:\n\tMissing key(s) in state_dict: \"conv1.0.weight\", \"conv1.0.bias\", \"conv1.1.weight\", \"conv1.1.bias\", \"conv1.1.running_mean\", \"conv1.1.running_var\", \"conv1.3.weight\", \"conv1.3.bias\", \"conv1.4.weight\", \"conv1.4.bias\", \"conv1.4.running_mean\", \"conv1.4.running_var\", \"conv2.0.weight\", \"conv2.0.bias\", \"conv2.1.weight\", \"conv2.1.bias\", \"conv2.1.running_mean\", \"conv2.1.running_var\", \"conv2.3.weight\", \"conv2.3.bias\", \"conv2.4.weight\", \"conv2.4.bias\", \"conv2.4.running_mean\", \"conv2.4.running_var\", \"conv3.0.weight\", \"conv3.0.bias\", \"conv3.1.weight\", \"conv3.1.bias\", \"conv3.1.running_mean\", \"conv3.1.running_var\", \"conv3.3.weight\", \"conv3.3.bias\", \"conv3.4.weight\", \"conv3.4.bias\", \"conv3.4.running_mean\", \"conv3.4.running_var\", \"conv3.6.weight\", \"conv3.6.bias\", \"conv3.7.weight\", \"conv3.7.bias\", \"conv3.7.running_mean\", \"conv3.7.running_var\", \"conv4.0.weight\", \"conv4.0.bias\", \"conv4.1.weight\", \"conv4.1.bias\", \"conv4.1.running_mean\", \"conv4.1.running_var\", \"conv4.3.weight\", \"conv4.3.bias\", \"conv4.4.weight\", \"conv4.4.bias\", \"conv4.4.running_mean\", \"conv4.4.running_var\", \"conv4.6.weight\", \"conv4.6.bias\", \"conv4.7.weight\", \"conv4.7.bias\", \"conv4.7.running_mean\", \"conv4.7.running_var\", \"fc.0.weight\", \"fc.0.bias\", \"fc.1.weight\", \"fc.1.bias\", \"fc.1.running_mean\", \"fc.1.running_var\", \"fc.4.weight\", \"fc.4.bias\", \"fc.5.weight\", \"fc.5.bias\", \"fc.5.running_mean\", \"fc.5.running_var\", \"fc.8.weight\", \"fc.8.bias\". \n\tUnexpected key(s) in state_dict: \"model_state_dict\", \"class_names\", \"test_accuracy\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      7\u001b[39m model = CustomCNN().to(device)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# 3. Load the weights\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 'map_location' ensures it works even if you move between CPU and GPU\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mintel_cnn_model.pth\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# 4. CRITICAL: Set to evaluation mode\u001b[39;00m\n\u001b[32m     14\u001b[39m model.eval()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/imgclass_cnn/.venv/lib/python3.14/site-packages/torch/nn/modules/module.py:2635\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2627\u001b[39m         error_msgs.insert(\n\u001b[32m   2628\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2629\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2630\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2631\u001b[39m             ),\n\u001b[32m   2632\u001b[39m         )\n\u001b[32m   2634\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2635\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2636\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2637\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2638\u001b[39m         )\n\u001b[32m   2639\u001b[39m     )\n\u001b[32m   2640\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for CustomCNN:\n\tMissing key(s) in state_dict: \"conv1.0.weight\", \"conv1.0.bias\", \"conv1.1.weight\", \"conv1.1.bias\", \"conv1.1.running_mean\", \"conv1.1.running_var\", \"conv1.3.weight\", \"conv1.3.bias\", \"conv1.4.weight\", \"conv1.4.bias\", \"conv1.4.running_mean\", \"conv1.4.running_var\", \"conv2.0.weight\", \"conv2.0.bias\", \"conv2.1.weight\", \"conv2.1.bias\", \"conv2.1.running_mean\", \"conv2.1.running_var\", \"conv2.3.weight\", \"conv2.3.bias\", \"conv2.4.weight\", \"conv2.4.bias\", \"conv2.4.running_mean\", \"conv2.4.running_var\", \"conv3.0.weight\", \"conv3.0.bias\", \"conv3.1.weight\", \"conv3.1.bias\", \"conv3.1.running_mean\", \"conv3.1.running_var\", \"conv3.3.weight\", \"conv3.3.bias\", \"conv3.4.weight\", \"conv3.4.bias\", \"conv3.4.running_mean\", \"conv3.4.running_var\", \"conv3.6.weight\", \"conv3.6.bias\", \"conv3.7.weight\", \"conv3.7.bias\", \"conv3.7.running_mean\", \"conv3.7.running_var\", \"conv4.0.weight\", \"conv4.0.bias\", \"conv4.1.weight\", \"conv4.1.bias\", \"conv4.1.running_mean\", \"conv4.1.running_var\", \"conv4.3.weight\", \"conv4.3.bias\", \"conv4.4.weight\", \"conv4.4.bias\", \"conv4.4.running_mean\", \"conv4.4.running_var\", \"conv4.6.weight\", \"conv4.6.bias\", \"conv4.7.weight\", \"conv4.7.bias\", \"conv4.7.running_mean\", \"conv4.7.running_var\", \"fc.0.weight\", \"fc.0.bias\", \"fc.1.weight\", \"fc.1.bias\", \"fc.1.running_mean\", \"fc.1.running_var\", \"fc.4.weight\", \"fc.4.bias\", \"fc.5.weight\", \"fc.5.bias\", \"fc.5.running_mean\", \"fc.5.running_var\", \"fc.8.weight\", \"fc.8.bias\". \n\tUnexpected key(s) in state_dict: \"model_state_dict\", \"class_names\", \"test_accuracy\". "
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imgclass_cnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
